{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information about international student numbers , their enrolments, nationality, field of study etc.\n",
    "\n",
    "Student numbers data is available from year 2002 till October 2020. However the data related to enrolments, commencements and field of study is available for 2019 and 2020 (till October).\n",
    "\n",
    "\n",
    "The data is available in 2 csv files mentioned below:\n",
    "\n",
    "1. studentsPublic.csv     ---> This file provides the actual student numbers in Australia by nationality and State.\n",
    "2. nationalitySummary.csv ---> This file provides details about field of study, total enrolments and commencements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the csv files .\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('../../data/studentPublic.csv')\n",
    "df2 = pd.read_csv('../../data/nationalitySummary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets examine the columns for both the files.\n",
    "\n",
    "all_cols = [list(df1.columns), list(df2.columns)]\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get an inersection to get the columns common in both the dataframes.\n",
    "\n",
    "my_function = lambda x, y: set(x).intersection(set(y))\n",
    "my_function(df1.columns, df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is clear from the above output that both the datasets provide completely different attributes related to international students in Australia. The columns common to both the dataseta are Month, Nationality and Year only. So, it is more appropriate to clean and analyse the datasets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecting and Cleaning the Student numbers data (studentsPublic.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the required modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the csv file and load into a dataframe.\n",
    "\n",
    "df_students = pd.read_csv('../../data/studentPublic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the type\n",
    "\n",
    "type(df_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the number of rows and columns in the student dataset.\n",
    "\n",
    "df_students.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get some information about the dataframe created earlier.\n",
    "\n",
    "df_students.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the list of columns present in the dataset.\n",
    "\n",
    "df_students.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising  the columns.\n",
    "df_students.columns = [col.lower() for col in df_students.columns]\n",
    "df_students.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the first few rows at the beginning of the data set.\n",
    "\n",
    "df_students.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get few rows at the end of the data set.\n",
    "\n",
    "df_students.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the count of missing values for all the coloumns\n",
    "\n",
    "df_students.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the columns have no missing values except last column, 'Growth'. This was mostly expected as the dataset is pre-processed available on the Department of Education website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The possible reason for missing 'growth'  column could be attributed to the fact that there may be no students for the previous year.\n",
    "## lets check this out\n",
    "\n",
    "null_data = df_students[df_students.isnull().any(axis=1)]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the data for one country (say Chad) where growth column is null/missing.\n",
    "\n",
    "null_data = null_data[(null_data.nationality == 'Chad') & (null_data.state == '_All')]\n",
    "null_data.sort_values(by = 'year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values\n",
    "It can be seen from the above outout that growth column is null for an year where there is no data for the previous year.\n",
    "Hence it is reasonable to fill the missing values with 0 for the growth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling the missing values with 0\n",
    "\n",
    "df_students = df_students.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the count of missing values for all the coloumns after 'fillna' operation\n",
    "\n",
    "df_students.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great, there are no missing values in the student dataset. Let us export the clean data into a new csv (studentsPublic_Clean.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students.to_csv('../../data/studentPublic_Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the cleaned csv file and load into a new dataframe.\n",
    "\n",
    "df_students_clean = pd.read_csv('../../data/studentPublic_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df_students_clean.duplicated()\n",
    "dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspecting and Cleaning the Student numbers data (nationalitySummary.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the csv file and load into a dataframe.\n",
    "\n",
    "df_enrol = pd.read_csv('../../data/nationalitySummary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the type\n",
    "\n",
    "type(df_enrol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the number of rows and columns in the student dataset.\n",
    "\n",
    "df_enrol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get some information about the dataframe created earlier.\n",
    "\n",
    "df_enrol.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the list of columns present in the dataset.\n",
    "\n",
    "df_enrol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising  the columns.\n",
    "df_enrol.columns = [col.lower() for col in df_enrol.columns]\n",
    "df_enrol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the first few rows at the beginning of the data set.\n",
    "\n",
    "df_enrol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get few rows at the end of the data set.\n",
    "\n",
    "df_enrol.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the count of missing values for all the coloumns\n",
    "\n",
    "df_enrol.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check this out for missing values.\n",
    "\n",
    "null_data1 = df_enrol[df_enrol.isnull().any(axis=1)]\n",
    "null_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the data for one country (say Niger) where enrolmentsgrowth column is null/missing.\n",
    "\n",
    "null_data1 = null_data1[(null_data1.nationality == 'Niger')]\n",
    "null_data1.sort_values(by = 'year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above outout that enrolmentsgrowth column is null for an year where there is no data for the previous year. e.g. 'Non AQF Award' has no enrolments in 2019. So, this is null for 2020.\n",
    "Hence it is reasonable to fill the missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling the missing values with 0\n",
    "\n",
    "df_enrol = df_enrol.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the count of missing values for all the coloumns after 'fillna' operation\n",
    "\n",
    "df_enrol.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great, there are no missing values in the enrolments dataset. Let us export the clean data into a new csv (nationalitySummary_Clean.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_enrol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrol.to_csv('../../data/nationalitySummary_Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the cleaned csv file and load into a new dataframe.\n",
    "\n",
    "df_enrol_clean = pd.read_csv('../../data/nationalitySummary_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df_enrol_clean.duplicated()\n",
    "dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrol_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrol_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
